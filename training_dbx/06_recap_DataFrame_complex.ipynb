{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create several separate DataFrames from the data using selects:\n",
    "# One dimension for the Customers containing customer, age, gender and zipcodeOri, unique of course.\n",
    "# One for the Merchants containing merchant, zipMerchant, also unique.\n",
    "# One fact-table for the Transactions with category, amount and fraud, ... and the columns to join both the merchant\n",
    "# and the customer back in again.\n"
   ],
   "id": "c6e67a66972807b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# How many customers are there? How many merchants and how many transactions?\n",
    "# Use your new DataFrames\n"
   ],
   "id": "40c9cd79fe2f99eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Which category of transaction causes the biggest total loss in frauds?\n",
    "# What amount is lost?\n",
    "# Use your new table for transactions\n"
   ],
   "id": "4ce114b83af8e3e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Which category has the highest single fraud case by amount?\n",
    "# Use your new table for transactions\n"
   ],
   "id": "36fe1b767bfbe2cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# How old is the customer that has the most fraud cases in travel.\n",
    "# Use your new DataFrames instead of the imported table via a join.\n"
   ],
   "id": "73d08e57c60ddfe3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Try calculating a share from the total loss per category that every\n",
    "# fraud is causing.\n",
    "# For example x% from all losses related to es_travel, and so on.\n",
    "# use windowing functions. see pyspark.sql Window\n",
    "\n"
   ],
   "id": "ca9fdc2fc7716649"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = spark.read.table(\"bs140513_032310\")\n",
   "id": "a7a3b76819633afe"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
